{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Authors: Andrea Jiménez Zuñiga e Isabel Afán de Ribera\n",
    "* Date: 04/12/2020\n",
    "* Institution: CUNEF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build an algorithmic model that helps us identify to what type of customers we could grant a loan based on a set of classification variables. To do this, we start with a database which contains customer information stydying this with an EDA. \n",
    "\n",
    "From this study, we have acquired a general idea of the data that helped us to treat the mentioned data. We have found variables with a high percentage of missing values, numerical and categorical variables, variables with outliers, etc. Therefore we have made a treatment of our data, where we have eliminated those variables that do not provide relevant information to our model, making decisions about whether to impute or eliminate missing values, treatment of outliers, treatment of variables, among others.\n",
    "As a result, we have selected a total of 25 of the most representative variables. \n",
    "\n",
    "Finally, we have developed models to be able to make predictions. These are: \n",
    "\n",
    "1. Model Baseline and Logistic Regression\n",
    "2. Support Vector Machine\n",
    "3. Random Forest\n",
    "4. XGBoost\n",
    "\n",
    "The results of these models indicate that the worst model and, therefore, the least suitable for making the decision to grant or not the credit to the candidate. This model is the Support Vector Machine because, despite having a higher accuracy than the logistic regression model, it is the model with the worst area under the curve. In addition, this model has a very high number of false positives, which means that it could suppose a great risk for the company because as many credits would be granted and would not be paid by the clients. \n",
    "\n",
    "The next worst model is the Logistic Regression model. This model has the ROC curve just like Random Forest and XGBoost. However, its accuracy is the worst as well as its error level.\n",
    "\n",
    "Our decision, therefore, is between the Random Forest model and the Bel XGboost. If we look at the accuracy of both models we can see that Random Forest's accuracy is slightly higher, at 76% compared to 75% for the XGboost. However, in both cases the ROC curve is the same so we need to look at the rest of the model evaluation measures. With respect to the confusion matrix, the Random Forest model predicts a higher number of false positives, which is not favourable as it implies a higher risk. In addition, the F1 score is somewhat higher in the XGBoost which indicates that this model has a better performance.\n",
    "\n",
    "For all these reasons, and the fact that the XGBoost requires less computational effort in terms of runtime, we have decided that the best model is the XGBoost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prestamos_env",
   "language": "python",
   "name": "prestamos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
